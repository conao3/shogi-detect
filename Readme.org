#+title: インテリジェントシステム 期末レポート
#+author: B151235 山下直哉
#+date: 2018/11/16
#+options: toc:nil

* Abstract
授業において様々な手法での機械学習の理論を学習した。
このレポートは、理論学習の演習として将棋の駒の識別モデルを作成したことについて、結果と展望を記すものである。
識別器作成にはMicrosoft Azureが提供している、Custom Visionを使用した。
Custom Visionは千代田による「松屋警察」(2007)[fn:1](98%の確率で松屋の牛丼を判定可能)など
有効なパフォーマンスを示した先行事例があり、手軽さも他のツールを圧倒している。
将棋の駒の判別として本来ならば、相手駒である反転駒を考慮して30クラス分類となるが、実際の対局のキャプチャ画像を使用したため
成銀の画像が入手できず、28クラス分類で識別器を作成した。
それぞれ100枚の画像を使用し、Precision:92.7%, Recall:90.0%の精度で識別ができる識別器を作成できた。
また、使用した全ツールはgithub[fn:6], Custom Vision[fn:7]にて公開した。

\begin{multicols*}{2}
* 先行事例研究
インターネット上において機械学習分野ではすぎゃーんがTensor Flowによるアイドル顔識別器(2016)[fn:2]、その後改良を加え
2000人のアイドル顔を自力でタグ付けし1000人程度の識別が可能な識別器(2017)[fn:3]などを作成し、機械学習の普及に寄与していた。

すぎゃーんのブログにおいて、将棋駒の分類を機械学習によって画像認識する話題[fn:4]があり、Tensor Flowの
学習済みモデルを適用し識別器を作成していた。
そこでは識別の精度は悪く、研究は失敗したかのように書かれていた。
しかし、学習画像と検定画像は大きく異なっており(図[[fig:sugyan]])、
これをもって機械学習による画像識別機が将棋駒の判別に向いていないと帰結させるのは早計に思えた。

そこで私はNHK杯の録画から盤面が映されているコマを画像として保存し、その画像に対して学習し、
NHK杯の画像に対して識別することでどれだけの精度を持つ識別機が作成できるか研究した。

#+name: fig:sugyan
#+caption: すぎゃーんが使用した学習画像と検定画像
#+attr_latex: :width 6cm :float nil
[[./imgs/sugyan.png]]
* データ作成
学習・検定データは以下の通り収集した。
1. NHK杯の映像を入手し、将棋盤の全面が写ったコマを手動で保存した。（盤面画像: 約200枚）
2. Pythonによる古典的な特徴解析により将棋盤領域を検出し、将棋盤領域のみの画像を作成した(図[[fig:python1]])。
3. Pythonにより将棋盤領域のみの画像を $9 \times 9$ のマス目画像にスライスした。（マス目画像: 約16,000枚）
4. PHPによるWebアプリケーションを作成し、手動で駒画像と空き画像に分類した（駒画像: 約5,000枚, 空白画像: 10,000枚: 33px \times 33px）
5. 前段のアプリケーションにより、手動で28クラス分類を行った(図[[fig:php1]])。
6. サンプル数の足りない駒画像についてはPythonによりランダムノイズを与え、学習データを増やした。

#+name: fig:python1
#+caption: Pythonによる古典的な特徴解析
#+attr_latex: :width 9cm :float nil
[[./imgs/python1.png]]

#+name: fig:php1
#+caption: PHPによるWebアプリケーションでの画像分類
#+attr_latex: :width 5.5cm :float nil
[[./imgs/php1.jpg]]
* 学習・性能分析
本研究では識別器作成機としてMicrosoft AzureのCustom Vision[fn:5]を選定した。
Custom Visionは1クラスにつき最低5枚、推奨50枚の画像を必要とし、画像をアップロード・タグ付けし、
「Train」ボタンを押すだけで識別器を作成できる。

Pythonによるランダムノイズを加え、各クラス3000枚の画像を用意したが、そのうち100枚の画像をアップロードし学習を行った。

結果としてPrecision: 92.7％, Recall: 90.0%の識別器を作成できた(図[[fig:azure1]])。
クラス別に正答率を見ていくと、「桂馬」や「歩」の識別率が高く、「香車」や「成桂」の識別率が低かった。

#+name: fig:azure1
#+caption: Custom Visionによる識別器作成, 評価
#+attr_latex: :width 4.5cm :float nil
[[./imgs/azure1.png]]
* 考察
実際の対局映像のキャプチャを利用しているため、クラスにおいては極端に元データの少ないクラスが現れていた。
例えば識別率の低い結果となった「香車(Recall: 77.2%)」については「歩」との混同が多い結果となった。
これは手動で分類する際にも目を細めて分類した難しい問題であり、もっと解像度の高い画像で行った場合、識別率が上がる可能性がある。
本研究においては1マスは33px正方形として正規化し扱ったため、100px正方形などでもう一度試してみたい。

また「成桂(Recall: 77.8%)」については、本研究において、NHK杯の実際の対局から画像を入手したため「成桂」の元データを収集することが困難で、
200枚の盤面データから収集できた「成桂」元データはわずか10枚だった。
そのため学習データの大部分をPythonのランダムノイズにより生成された画像であり、それに由来し正答率が低くなってしまったと考えられる。

今後はTensor Flowなどを利用してDeep learningを利用した識別器を作成したい。
\end{multicols*}
* Footnotes
[fn:1] ちょまどMadoka @chomado
https://twitter.com/chomado/status/898812060624068609 - 2018/11/16 閲覧

[fn:2] TensorFlowによるアイドル顔識別器の話 - 2016.12.13 TensorFlow User Group #2
https://qiita.com/sugyan/items/f89cba95d67ab297d306 - 2018/11/16 閲覧

[fn:3] TensorFlow と出会った「ドルヲタ」エンジニアが1年かけてたどり着いた境地 － LINE すぎゃーん（sugyan）氏
https://press.forkwell.com/entry/2017/03/22/085525 - 2018/11/16 閲覧

[fn:4] 将棋駒画像の分類器をラクして作る
https://memo.sugyan.com/entry/2018/05/02/182830 - 2018/11/16 閲覧

[fn:5] Microsoft Azure - Custom Vision
https://www.customvision.ai - 2018/11/16 閲覧

[fn:6] Detect Shogi-peacies by deep-leaning AI - conao3/shogi-detect
https://github.com/conao3/shogi-detect - 2018/11/16 閲覧

[fn:7] Microsoft Azure - Custom Vision - Conao:Shogi-detect2
https://www.customvision.ai/projects/135388ba-c306-4ab4-b68d-9bfdcf671a0d#/performance
